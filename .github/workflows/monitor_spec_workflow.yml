name: Daily Monitor Spec Crawler

on:
  schedule:
    - cron: '30 15 * * *'  # í•œêµ­ì‹œê°„ ìì • 30ë¶„
  workflow_dispatch:

jobs:
  split-and-crawl:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [0, 1, 2, 3, 4]  # ì´ 5ë¶„í•  â†’ ìµœëŒ€ ì•½ 1200ê°œì”© í¬ë¡¤ë§
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install Chrome & Chromedriver
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip curl
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -f install -y
          sudo apt-get install -y google-chrome-stable
          CHROME_VERSION=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+\.\d+')
          DOWNLOAD_URL="https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${CHROME_VERSION}/linux64/chromedriver-linux64.zip"
          wget $DOWNLOAD_URL -O chromedriver.zip || (echo "âŒ ë“œë¼ì´ë²„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨" && exit 1)
          unzip chromedriver.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver
          chromedriver --version
          google-chrome --version

      - name: Install Python dependencies
        run: pip install selenium pandas

      - name: Run monitor list crawler (1ë²ˆë§Œ ì‹¤í–‰)
        if: matrix.chunk == 0
        run: python monitor_crawler_batch.py

      - name: Split monitor_list.csv
        run: |
          python -c "
import pandas as pd
df = pd.read_csv('monitor_list.csv')
chunks = [df[i::5] for i in range(5)]
for idx, chunk in enumerate(chunks):
    chunk.to_csv(f'monitor_list_{idx}.csv', index=False)
"

      - name: Run monitor spec crawler for chunk
        run: |
          cp monitor_list_${{ matrix.chunk }}.csv monitor_list.csv
          python monitor_spec_crawler.py
          mv monitor_spec_list.csv monitor_spec_list_${{ matrix.chunk }}.csv

      - name: Upload partial result
        uses: actions/upload-artifact@v3
        with:
          name: monitor_spec_list_${{ matrix.chunk }}
          path: monitor_spec_list_${{ matrix.chunk }}.csv

  merge-and-commit:
    needs: split-and-crawl
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Download all chunks
        uses: actions/download-artifact@v3
        with:
          path: chunks

      - name: Merge all chunks
        run: |
          mkdir merged
          cat chunks/*/*.csv | grep -v '^ìƒí’ˆì½”ë“œ' > merged/all.csv
          echo "ìƒí’ˆì½”ë“œ,ëª¨ë¸ëª…,ê°€ê²©,ì¸ì¹˜,í•´ìƒë„,ì£¼ì‚¬ìœ¨,íŒ¨ë„" > monitor_spec_list.csv
          cat merged/all.csv >> monitor_spec_list.csv

      - name: Commit and push result CSVs
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          git config --global user.name "kwondohoon1"
          git config --global user.email "kwondohoon1@naver.com"
          git pull origin main || true
          git add monitor_spec_list.csv
          git commit -m "ğŸ“Š ìŠ¤í™ ë¦¬ìŠ¤íŠ¸ ìë™ ë³‘í•© ì—…ë°ì´íŠ¸" || echo "âœ… ë³€ê²½ ì—†ìŒ"
          git remote set-url origin https://x-access-token:${GH_TOKEN}@github.com/kwondohoon1/danawa-monitor-crawler.git
          git push origin main || echo "âŒ Push ì‹¤íŒ¨"
