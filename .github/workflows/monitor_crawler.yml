name: Daily Monitor Crawler

on:
  schedule:
    - cron: '0 0 * * *'  # 매일 자정(UTC)
  workflow_dispatch:      # 수동 실행도 허용

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        pip install selenium pandas
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
        which chromedriver || echo "❌ chromedriver 설치 실패"
        sudo ln -sf $(which chromedriver) /usr/bin/chromedriver || true
        chromedriver --version || echo "chromedriver 실행 안됨"

    - name: Run monitor crawler
      run: python monitor_crawler_batch.py

    - name: Commit result
      env:
        GH_TOKEN: ${{ secrets.GH_TOKEN }}
      run: |
        git config --global user.name "kwondohoon1"
        git config --global user.email "kwondohoon1@naver.com"
        git pull origin main || true
        git add monitor_list.csv
        git commit -m "📊 monitor_list.csv 자동 업데이트" || echo "변경 없음"
        git push https://kwondohoon1:${GH_TOKEN}@github.com/kwondohoon1/danawa-monitor-crawler.git || echo "❌ Push 실패"