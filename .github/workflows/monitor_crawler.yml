name: Daily Monitor Crawler

on:
  schedule:
    - cron: '0 0 * * *'  # 매일 자정(UTC 기준)
  workflow_dispatch:      # 수동 실행 허용

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install Google Chrome & Chromedriver
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt install -y ./google-chrome-stable_current_amd64.deb
        LATEST=$(curl -sSL https://chromedriver.storage.googleapis.com/LATEST_RELEASE)
        wget https://chromedriver.storage.googleapis.com/${LATEST}/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/bin/chromedriver
        sudo chmod +x /usr/bin/chromedriver
        which chromedriver && chromedriver --version
        which google-chrome && google-chrome --version

    - name: Install Python dependencies
      run: pip install selenium pandas

    - name: Run monitor crawler
      run: python monitor_crawler_batch.py

    - name: Commit result
      env:
        GH_TOKEN: ${{ secrets.GH_TOKEN }}
      run: |
        git config --global user.name "kwondohoon1"
        git config --global user.email "kwondohoon1@naver.com"
        git pull origin main || true
        git add monitor_list.csv
        git commit -m "📊 monitor_list.csv 자동 업데이트" || echo "변경 없음"
        git push https://kwondohoon1:${GH_TOKEN}@github.com/kwondohoon1/danawa-monitor-crawler.git || echo "❌ Push 실패""