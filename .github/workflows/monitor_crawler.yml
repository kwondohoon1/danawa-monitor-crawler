name: Daily Monitor Crawler

on:
  schedule:
    - cron: '0 0 * * *'  # ë§¤ì¼ ìì •(UTC)
  workflow_dispatch:      # ìˆ˜ë™ ì‹¤í–‰ë„ í—ˆìš©

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        pip install selenium pandas
        sudo apt-get update
        sudo apt-get install -y chromium-chromedriver
        which chromedriver || echo "âŒ chromedriver ì„¤ì¹˜ ì‹¤íŒ¨"
        sudo ln -sf $(which chromedriver) /usr/bin/chromedriver || true
        chromedriver --version || echo "chromedriver ì‹¤í–‰ ì•ˆë¨"

    - name: Run monitor crawler
      run: python monitor_crawler_batch.py

    - name: Commit result
      env:
        GH_TOKEN: ${{ secrets.GH_TOKEN }}
      run: |
        git config --global user.name "kwondohoon1"
        git config --global user.email "kwondohoon1@naver.com"
        git pull origin main || true
        git add monitor_list.csv
        git commit -m "ğŸ“Š monitor_list.csv ìë™ ì—…ë°ì´íŠ¸" || echo "ë³€ê²½ ì—†ìŒ"
        git push https://kwondohoon1:${GH_TOKEN}@github.com/kwondohoon1/danawa-monitor-crawler.git || echo "âŒ Push ì‹¤íŒ¨"